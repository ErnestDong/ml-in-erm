\documentclass{ctexbeamer}
\usepackage[backend = biber, style = gb7714-2015, url=false,gbtitlelink=true]{biblatex}
\addbibresource{ref.bib}
\usepackage{xeCJK}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{minted}
\usepackage{hyperref}
\usetheme{CambridgeUS}
\author{董晨阳}
\date{\today}
\title{机器学习在企业风险管理中的应用举例}
\setbeamertemplate{bibliography item}{}
\setbeamertemplate{bibliography entry article}{}
\setbeamertemplate{bibliography entry title}{}
\setbeamertemplate{bibliography entry location}{}
\setbeamertemplate{bibliography entry note}{}
\begin{document}

\AtBeginSection[]
{
    \small\begin{frame}
        \frametitle{目录}
        \tableofcontents[
            sectionstyle=show/shaded,
            subsectionstyle=show/show/hide,
            subsubsectionstyle=show/show/show/hide
        ]
    \end{frame}
}
\maketitle
\begin{frame}
    \frametitle{目录}
    \tableofcontents[hideallsubsections]
    笔记版本见 \url{https://ernestdong.github.io/posts/machine_learning_in_erm/}，所有源代码见
\end{frame}

\section{前言}
\subsection{机器学习概述}
\begin{frame}
    \frametitle{何谓“机器学习”}
    \begin{columns}
        \column{0.6\linewidth}
        \includegraphics[width=.9\textwidth]{/Users/dcy/Code/ernest/static/images/xkcd/1838.png}
        \column{0.35\linewidth}
        什么是学习？

        \href{https://zh.wikipedia.org/wiki/\%E5\%AD\%A6\%E4\%B9\%A0}{维基百科}上说学习是获得新的理解、知识、行为、技能、价值观、态度和偏好的过程。

        在计算技术快速发展的今天，让机器去利用算法和算力去“学习”、推理、决策，就是机器学习。
    \end{columns}
\end{frame}
\subsection{机器学习的分类}
\begin{frame}
    \frametitle{机器学习的分类}
    \begin{columns}
        \column{0.6\linewidth}
        \includegraphics[width=.9\textwidth]{../lib/机器学习.jpeg}
        \column{0.35\linewidth}
        机器学习深究的话，需要学习很多数学和计算机知识。
        但是工业界将常用的机器学习算法封装地很好（如pytorch, scikit-learn），几行代码就可以实现一个模型。

        本文主要参考了\textcite{scikit-learn}的文档，在编码过程中阅读文档是有帮助的。
    \end{columns}
\end{frame}
% \subsection{一点建议}
% \begin{frame}
%     \frametitle{要学习机器学习吗？}
%     \begin{itemize}
%         \item 了解一下常见算法的思想和适用场景
%         \item 学好专业课和数学
%         \item 有问题查文档
%     \end{itemize}
% \end{frame}
\section{机器学习预测信用评级}
\subsection{数据预处理}
\begin{frame}
    \frametitle{数据来源}
    数据来自 \href{https://www.kaggle.com/datasets/agewerc/corporate-credit-rating}{kaggle}。
    涵盖了 2029 家美国上市公司信用评级的历史数据。数据除了公司基本信息外，还包括了30个财务特征：

    \begin{enumerate}
        \item 流动性指标: currentRatio, quickRatio, cashRatio, daysOfSalesOutstanding
        \item 盈利能力: grossProfitMargin, operatingProfitMargin, pretaxProfitMargin, netProfitMargin, effectiveTaxRate, returnOnAssets, returnOnEquity, returnOnCapitalEmployed
        \item 负债比率: debtRatio, debtEquityRatio
        \item 营运表现: assetTurnover, fixedasset
        \item 现金流指标: operatingCashFlowPerShare, freeCashFlowPerShare, cashPerShare, operatingCashFlowSalesRatio, freeCashFlowOperatingCashFlowRatio
    \end{enumerate}
\end{frame}
\begin{frame}[fragile]
    \frametitle{数据简单处理}
    评级分布如图\ref{rating}所示。
    我们会合并 C/CC/CCC 的评级，选取 3/4 作为训练集，1/4 作为测试集。
    \begin{figure}
        \includegraphics[width=0.6\linewidth]{../lib/rating.png}
        \label{rating}
        \caption{评级分布}
    \end{figure}
\end{frame}
\begin{frame}[fragile]
    \frametitle{数据简单处理}
    \begin{minted}{python}
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
df = pd.read_csv("./corporate_rating.csv", encoding="utf-8")
Y = df["Rating"].replace({"CCC": "C", "CC": "C"})
df["Date"] = df["Date"].apply(lambda x: x.split("/")[-1])
dummies = ["Rating Agency Name", "Sector", "Date"]
X = df[[i for i in df.columns if df[i].dtype != "object"]]
X = pd.concat([X]+[pd.get_dummies(df[i], drop_first=True)
    for i in dummies]),
    axis=1)
Xtrain, Xtest, Ytrain, Ytest = train_test_split(
    X, Y, test_size=0.25, random_state=42
)
\end{minted}
\end{frame}
\begin{frame}
    \frametitle{评价机器学习效果的指标}
    对于二分类问题，一个样本真实情况可能是 True/False，对应预测可能是 Positive/Negative。
    \begin{center}
        \begin{tabular}{lll}
                     & True & False \\
            Positive & TP   & FP    \\
            Negative & TN   & FN    \\
        \end{tabular}
    \end{center}
    准不准的定义有这么几种：
    \begin{eqnarray}
        precision & = & TP / (TP + FP) \\
        recall & = & TP / (TP + FN) \nonumber\\
        F1 & = & \frac{precision\cdot recall}{precision+recall}\nonumber
    \end{eqnarray}
    分别为 预测阳性中真实为正的概率、样本中的正例有多少被预测正确、以及二者的调和平均。
\end{frame}

\begin{frame}[fragile]
    \frametitle{评价机器学习效果的指标}
    除此之外，我们再来比较一下“相关系数”，看一看预测差异是否很大。
    \begin{minted}{python}
def get_score(Xtest, Ytrue, model):
    Ypred = model(Xtest)
    avg = "weighted"
    rating_map = {i: ord(i[0]) * 100 - len(i)
                    for i in Y.unique()}
    return {
        "precision":
            precision_score(Ytrue, Ypred, average=avg),
        "recall": recall_score(Ytrue, Ypred, average=avg),
        "f1": f1_score(Ytrue, Ypred, average=avg),
        "\(R^2\)": pearsonr(
            [rating_map[i] for i in Ypred],
            [rating_map[i] for i in Ytest]
        )[0],
    }
\end{minted}
\end{frame}

\begin{frame}[fragile]
    \frametitle{评价机器学习效果的指标}
    除此之外，我们再来比较一下“相关系数”，看一看预测差异是否很大。
    \begin{minted}{python}
def get_score(Xtest, Ytrue, model):
    Ypred = model(Xtest)
    avg = "weighted"
    rating_map = {i: ord(i[0]) * 100 - len(i)
                    for i in Y.unique()}
    return {
        "precision":
            precision_score(Ytrue, Ypred, average=avg),
        "recall": recall_score(Ytrue, Ypred, average=avg),
        "f1": f1_score(Ytrue, Ypred, average=avg),
        "\(R^2\)": pearsonr(
            [rating_map[i] for i in Ypred],
            [rating_map[i] for i in Ytest]
        )[0],
    }
\end{minted}
\end{frame}
\begin{frame}
    \frametitle{完全随机的情况}
    如果我们训练的分类器完全无效，那么结果是
    \begin{center}
        \begin{tabular}{ll}
            precision & 0.2364 \\
            recall    & 0.1254 \\
            f1        & 0.1544 \\
            \(R^2\)   & 0.0089 \\
        \end{tabular}
    \end{center}
\end{frame}
\subsection{经典机器学习算法}
\subsubsection{从logit模型开始}
\begin{frame}[fragile]
    \frametitle{logit 模型}
    关于分类我们自然地想到了 logit 回归。我们不妨以 logit 回归为切入点看一看 sklearn 是如何训练模型的：

    \begin{minted}{python}
from sklearn.linear_model import LogisticRegression
logit = LogisticRegression(solver="saga", 
            multi_class="multinomial", random_state=42)
logit.fit(Xtrain, Ytrain)
logit.predict(Xtest)
    \end{minted}

    \begin{center}
        \begin{tabular}{ll}
            precision & 0.1815  \\
            recall    & 0.2440  \\
            f1        & 0.1547  \\
            \(R^2\)   & -0.0177 \\
        \end{tabular}
    \end{center}
\end{frame}
\subsubsection{基于树的算法}
\begin{frame}[fragile]
    \frametitle{决策树}

    决策树直观上很好理解，也是我们今天少数可解释的模型。一个数据集有多个特征，每个节点按照某个特征是否满足一定的条件分叉，形成一棵二叉树。

    该节点选取特征分叉的决策依据是最大化“信息增益”，即分叉前后数据更“有序”，且更有序的程度最大（信息熵变化最大）。
    这棵树为了避免过拟合，我们会对决策树“剪枝”，增加一些分支条件的限制，可以看\href{https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html}{sklearn 文档}。
    \begin{center}
        \begin{figure}
            \includegraphics[width=0.8\linewidth]{/Users/dcy/Desktop/thesis/data/decision_tree.png}
            \label{decisiontree}
            \caption{决策树}
        \end{figure}
    \end{center}
\end{frame}
\begin{frame}
    \frametitle{集成学习}
    决策树一般是一种比较弱的分类器。集成学习则是利用多个弱分类器的集成，形成一个强分类器。

    组合的方法常见的有两种：bagging 和 boosting。bagging 是平行地训练弱分类器然后投票，特点是不容易过拟合。
    典型的随机森林就是随机地选取样本和特征训练出一棵棵决策树后投票，如图 \ref{randomforest} 所示。
    \begin{center}
        \begin{figure}
            \includegraphics[width=0.8\linewidth]{../lib/rf.png}
            \label{randomforest}
            \caption{随机森林}
        \end{figure}
    \end{center}

\end{frame}
\begin{frame}
    \frametitle{集成学习}
    使用 boosting 的梯度提升树可以树的深度很少就能达到很高的精度。
    boosting 迭代地训练一系列的分类器，每个分类器采用的样本分布都和上一轮的学习结果有关，直观比方是每个树都去学习上一个树没有学习好的地方。
    \begin{center}
        \begin{figure}
            \includegraphics[width=0.6\linewidth]{../lib/boosting.png}
            \label{boosting}
            \caption{梯度提升树}
        \end{figure}
    \end{center}
\end{frame}
\begin{frame}[fragile]
    \frametitle{基于树的算法代码}
    \begin{minted}{python}
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
dt = DecisionTreeClassifier(max_depth=3, random_state=42)
dt.fit(Xtrain, Ytrain)
rf = RandomForestClassifier(max_depth=4, random_state=42)
rf.fit(Xtrain, Ytrain)
gb = GradientBoostingClassifier(max_depth=3, random_state=42)
gb.fit(Xtrain, Ytrain)
    \end{minted}
    \begin{center}
        \begin{tabular}{l|cccc}
            model & precision & recall & f1     & \(R^2\) \\ \hline
            决策树   & 0.3498    & 0.3799 & 0.3529 & 0.3632  \\
            随机森林  & 0.3960    & 0.4251 & 0.3835 & 0.3995  \\
            梯度提升树 & 0.5305    & 0.5256 & 0.5095 & 0.5421  \\
        \end{tabular}
    \end{center}
\end{frame}
\subsubsection{基于距离的算法}
\begin{frame}
    \frametitle{支持向量机}
    SVM 的思想是样本分布在空间中，找到一个可以恰好划分开样本点、并且间隔最大的的（超）平面。
    
    当然这样的超平面不一定好找，我们可以用加入惩罚项的“软间隔”优化或者利用“核函数”将空间映射为可分的。
    
    \begin{center}
        \begin{figure}
            \includegraphics[width=0.6\linewidth]{../lib/SVM.jpeg}
            \caption{Support Vector Machine}
        \end{figure}
    \end{center}
\end{frame}
\begin{frame}
    \frametitle{K 近邻}

\end{frame}
\begin{frame}
    \frametitle{K Means}
    
\end{frame}
\subsection{神经网络}
\subsubsection{多层感知机}
\begin{frame}
    \frametitle{梯度下降与反向传播}
\end{frame}
\begin{frame}
    \frametitle{激活函数}
\end{frame}
\begin{frame}
    \frametitle{实现一个简单的感知机}
\end{frame}
\subsubsection{CNN}
\begin{frame}
    \frametitle{卷积}
\end{frame}
\begin{frame}
    \frametitle{实现 CNN}
\end{frame}
\subsubsection{RNN}
\begin{frame}
    \frametitle{“记忆”}
\end{frame}
\begin{frame}
    \frametitle{实现 LSTM}
\end{frame}
\subsection{对比}
\begin{frame}
    \frametitle{结果对比}
\end{frame}
\section{机器学习在企业风险管理中的应用}

\begin{frame}
    \frametitle{机器学习在企业风险管理中的应用}
    \Textcite{mai2019deep} 利用 CNN 预测企业破产，在处理文本数据时利用 word embedding 量化，AUC 曲线如图
    \includegraphics[width=\linewidth]{../lib/mlinerm.jpg}
\end{frame}
\begin{frame}
    \frametitle{机器学习在企业风险管理中的应用}
    \Textcite{kellner2022opening} 利用神经网络预测违约损失 Loss Given Default。

    他们将传统的分位数回归的回归元作为第一层，通过神经网络揭示其中的非线性关系，比如交叉项及其他非线性关系，神经网络最后一层是传统的分位数回归。利用 first order feature importance，量化输入变量的整体重要性。同时排除掉二阶的和交互的在分位数中接近于零。因此 QRNN 和分位数 QR 的分位数损失非常相似
    通过允许分位数回归神经网络实现的分位数中的非线性和相互作用来扩展这种方法。这种方法大大增强了建模的灵活性。额外的灵活性在更好地分布拟合和超时样本方面带来了回报，分位数预测精度提高了 30\%，同时更加 robust 。
\end{frame}
\begin{frame}
    \frametitle{机器学习在企业风险管理中的应用}
    \Textcite{golbayani2020comparative}
    使用决策树、随机森林、支持向量机和多层感知器应用于相同的数据集，预测公司未来评级。他们统计了机器学习在债券评级和公司信用评级方面的文章，很多认为 SVM 和神经网络是比较准确的。但是他们使用 Notches Distance 来对机器学习绩效来打分，认为基于决策树的两种方法更有效。

    当前机器学习最火热的两个应用方向是计算机视觉 CV 和自然语言处理 NLP ，亦有一些文献利用自然语言处理分析文本数据做研究。
\end{frame}

% 	\begin{block}{支持向量机}
% 		Support Vector Machine, SVM 是一种二分类器，其思想是样本分布在空间中，找到一个可以划分开样本点、并且间隔最大的的（超）平面。直观上间隔最大是为了让模型更稳健。

% 		\begin{figure}[htbp]
% 			\centering
% 			\includegraphics[width=.9\linewidth]{/Users/dcy/.emacs.d/.local/cache/org-persist/f7/54efd2-975c-422b-b3ad-490e521a7ad6-7a04fc95b8d271df5ad99ba7227f22de.jpg}
% 			\caption{SVM 图示}
% 			\label{fig:org76cd969}
% 		\end{figure}

% 		最简单的线性的硬间隔可分的如图 \ref{fig:org76cd969} 所示，当然这是比较理想的情况。当样本分布更复杂的时候，我们会选择软间隔，即将之前的硬间隔最大化条件放宽一点，允许部分点出错，在优化函数中加入惩罚项。

% 		如果还是不可以，我们会运用核函数来推导到非线形的情况，简单说就是将低维的样本点映射到高维空间，使样本线性可分。例如内积平方的核函数，\(K(v_1,V_2)=(x_1x_2+y_1y_2)^2\)，可以看作是三维空间中 \((x_i^2,\sqrt{2}x_iy_i,y_i^2)\) 两个点之间的距离


% 		\begin{verbatim}
% from sklearn.svm import SVC

% svm = SVC(kernel="rbf", gamma="auto", random_state=RANDOM_STATE)
% svm.fit(Xtrain, Ytrain)
% result["svm"] = get_score(Xtest, Ytest, svm.predict)
% result["svm"]
% \end{verbatim}
% 	\end{block}

% 	\begin{block}{KNN}
% 		这里的 NN 不是后文的 CNN 等的神经网络，全称是K Nearest Neighbors，意思是某个点分类取决于 K 个最近的邻居

% 		\begin{verbatim}
% from sklearn.neighbors import KNeighborsClassifier
% from sklearn.metrics import accuracy_score

% KNN = KNeighborsClassifier(n_neighbors=3)
% KNN.fit(Xtrain, Ytrain)
% result["KNN"] = get_score(Xtest, Ytest, KNN.predict)
% result["KNN"]
% \end{verbatim}
% 	\end{block}

% 	\begin{block}{K means}
% 		\begin{quote}
% 			有四个牧师去郊区布道，一开始牧师们随意选了几个布道点，并且把这几个布道点的情况公告给了郊区所有的村民，于是每个村民到离自己家最近的布道点去听课。

% 			听课之后，大家觉得距离太远了，于是每个牧师统计了一下自己的课上所有的村民的地址，搬到了所有地址的中心地带，并且在海报上更新了自己的布道点的位置。

% 			牧师每一次移动不可能离所有人都更近，有的人发现A牧师移动以后自己还不如去B牧师处听课更近，于是每个村民又去了离自己最近的布道点……

% 			就这样，牧师每个礼拜更新自己的位置，村民根据自己的情况选择布道点，最终稳定了下来。
% 		\end{quote}

% 		之前提到的算法都需要对数据进行一定的标注，标好某些数据属于某个分类，也就是常说的“监督学习”。K-means 是一种无监督学习，我们不需要声明训练中的哪些数据是哪个分类。

% 		K-means 的方法是，选择初始化的 k 个样本作为初始聚类中心 \(a_i\)  ，针对数据集中每个样本 \(x_i\)
% 		计算它到 k 个聚类中心的距离，并将其分到距离最小的聚类中心所对应的类中；重新计算每个类别的质心作为聚类中心 \(a_i\) ，再重复上面的过程，直至聚类中心“稳定”下来。
% 		\begin{verbatim}
% from sklearn.cluster import KMeans
% import numpy as np
% X = np.array([[1, 2], [1, 4], [1, 0],
%               [10, 2], [10, 4], [10, 0]])
% kmeans = KMeans(n_clusters=2, random_state=0).fit(X)
% kmeans.predict([[0, 0], [12, 3]])
% \end{verbatim}
% 	\end{block}

% 	\begin{block}{深度学习/神经网络}
% 		深度学习以神经网络为基础。神经网络是一种模仿生物神经系统结构和功能的数学模型，对函数进行估计和近似。
% 		\begin{block}{多层感知机}
% 			是深度学习的入门算法，误差反向传播 Backpropagation，刺激正向传播后通过梯度下降的方式最小化误差反向传播更新权值（最小化的方式是“梯度下降”）。它的信息处理能力来源于简单非线性函数的多次复合。

% 			\begin{block}{梯度下降与反向传播}
% 				我们用最小二乘法来理解“梯度下降”和“反向传播”
% 				\begin{verbatim}
% import torch
% x = torch.rand([500,1]) # X 是一个 tensor ，可以把他想象成 500x1 的向量
% y_true = 3*x+8
% learning_rate = 0.05 # learning rate 是每次梯度下降的“步长”
% w = torch.rand([1,1], requires_grad=True) # w 和 b 我们要 pytorch 自动求导
% b = torch.tensor(0, requires_grad=True, dtype=torch.float32)
% for i in range(500):
%     y_pred = torch.matmul(x,w)+b # 预测是多少
%     loss = (y_true-y_pred).pow(2).mean() # 损失
%     if w.grad is not None: # 把上一次的梯度清零
%         w.grad.data.zero_()
%     if b.grad is not None:
%         b.grad.data.zero_()
%     loss.backward() # 误差反向传播，得到 w 和 b 的梯度
%     w.data = w.data - w.grad*learning_rate # 梯度下降找到新的 w 和 b
%     b.data = b.data - b.grad*learning_rate
%     if i % 50 == 0:
%         print(w.item(), b.item(), loss.item())
% \end{verbatim}

% 				上述的代码在 pytorch 中对应的有：
% 				\begin{center}
% 					\begin{tabular}{ll}
% 						\texttt{for} 循环里面的模型 & \texttt{nn.Module} 封装好了许多模型     \\
% 						\texttt{loss} 的定义    & torch 中也有多种计算方式                 \\
% 						\texttt{loss} 的计算    & 优化器 \texttt{nn.optim} 中提供了许多优化器 \\
% 					\end{tabular}
% 				\end{center}
% 				通过 pytorch 我们可以写成
% 				\begin{verbatim}
% import torch
% from torch import nn
% from torch import optim

% x = torch.rand([50,1])
% y = 3*x+8

% class Lr(nn.Module):
%     def __init__(self):
%         super(Lr, self).__init__()
%         self.layer = nn.Linear(1,1)
%     def forward(self, x):
%         return self.layer(x)
% model = Lr()
% criterion = nn.MSELoss()
% optimizer = optim.SGD(model.parameters(), lr=0.05)
% for i in range(500):
%     out = model(x)
%     loss = criterion(y, out)
%     optimizer.zero_grad()
%     loss.backward()
%     optimizer.step()
% list(model.parameters())
% \end{verbatim}
% 			\end{block}

% 			\begin{block}{激活函数}
% 				\begin{center}
% 					\includegraphics[width=.9\linewidth]{/Users/dcy/.emacs.d/.local/cache/org-persist/a5/33e8f3-957f-4118-91ff-9b3a2685e344-56aa00e79e9dc112af2b3e3d430c8528.png}
% 				\end{center}

% 				神经网络本意是想模仿神经元。高中我们学过神经受到刺激后不一定会产生电信号，而是需要达到阈值后才能产生动作电位。因此当神经网络的输入层收到信号传导给隐藏层后，隐藏层是直接向输出层传导（这样的话通过神经网络线性函数的叠加仍然是一个线性函数），而是要经历一个非线性的“激活函数”，如 \texttt{relu} , \texttt{sigmoid}, \texttt{softsign} ，然后再进行传导。即针对 \(X\) 输入，神经元输出会是 \(f(W^TX+b)\) 。

% 				我们可以在这里可视化地理解一下
% 				\url{https://playground.tensorflow.org/}
% 			\end{block}
% 			\begin{block}{一个尝试}
% 				这是我用两层神经网络的代码
% 				\begin{verbatim}
% from torch import nn
% import torch
% torch.manual_seed(42)
% Ytrain_nn = pd.get_dummies(Ytrain)
% encode = Ytrain_nn.columns
% Ytrain_nn = torch.tensor(Ytrain_nn.values, dtype=torch.float32)
% Xtrain_nn = torch.tensor(Xtrain.values, dtype=torch.float32)

% hidden_layer = 40
% net = nn.Sequential(
%     nn.Linear(Xtrain_nn.shape[1], hidden_layer),
%     nn.ReLU(),
%     nn.Linear(hidden_layer, len(encode)),
%     nn.Softmax(dim=1),
% )
% optimizer = torch.optim.SGD(net.parameters(), lr=0.001)
% loss_func = torch.nn.MSELoss()

% for t in range(10000):
%     prediction = net(Xtrain_nn)
%     loss = loss_func(Ytrain_nn, prediction)
%     optimizer.zero_grad()
%     loss.backward()
%     optimizer.step()
% Xtest_nn = torch.tensor(Xtest.values, dtype=torch.float32)
% prediction = pd.DataFrame(net(Xtest_nn).detach().numpy())
% Ypredict = prediction.idxmax(axis=1).map(lambda x: encode[x])
% result["bp neural network"] = get_score(Xtest, Ytest, lambda _: Ypredict)
% result["bp neural network"]
% \end{verbatim}
% 			\end{block}
% 		\end{block}

% 		\begin{block}{CNN}
% 			所谓卷积神经网络，就是用卷积核扫描，类似“锐化”，是一种比较经典的计算机视觉算法。图片之间的像素是有关系的，刚刚的神经网络显然没有考虑到连续像素的关联性，CNN 通过做卷积将关系呈现出来。
% 			\begin{center}
% 				\includegraphics[width=.9\linewidth]{/Users/dcy/.emacs.d/.local/cache/org-persist/da/21d33e-ccf0-49f3-8b8f-bd424c5d6978-011bffe9337373ece605a2705d648ce1.jpg}
% 			\end{center}

% 			\href{https://zh.m.wikipedia.org/zh-hans/\%E5\%8D\%B7\%E7\%A7\%AF}{卷积}有其数学定义 \((f*g)(n) = \int_{-\infty}^{\infty}f(\tau)g(n-\tau)\mathrm{d}\tau\)，简单地理解就是两个函数 \texttt{f} 和 \texttt{g} ，先对g函数进行翻转，相当于在数轴上把 \texttt{g} 函数从右边“卷”到左边去。然后再把 \texttt{g} 函数平移到 \texttt{n} ，在这个位置对两个函数的对应点相乘，然后相加（“积”）。

% 			卷积神经网络先用卷积层扫描出特征，然后利用“池化”增强稳健性防止过拟合，最后一个全连接层处理输出。图像可以由二维的位置和第三维（颜色 RGB ）确定，在 \texttt{pytorch} 中常用 \texttt{Conv2d} 。而我们的数据则是一条条的，望文生义应该用 \texttt{Conv1d} （其实会用在自然语言处理中，但 RNN 应用更多）。

% 			从这里开始利用 CPU 训练比较慢，有 NVIDIA GPU 的同学可以尝试在 GPU 上训练
% 			\begin{verbatim}
% class CNN(nn.Module):
%     def __init__(self) -> None:
%         super(CNN, self).__init__()
%         self.conv = nn.Sequential(
%             nn.Conv1d(Xtrain_nn.shape[1], 20, 3, padding=3),
%             nn.Tanh(),
%             nn.AvgPool1d(2),
%         )
%         self.fc = nn.Sequential(
%             nn.Linear(40, len(encode)),
%             nn.ReLU(),
%             nn.Softmax(dim=1),
%         )

%     def forward(self, x):
%         out = self.conv(x)
%         out = out.view(out.size(0), -1)
%         out = self.fc(out)
%         return out
% Xtrain_cnn = Xtrain_nn.unsqueeze(2)
% Xtest_cnn = Xtest_nn.unsqueeze(2)
% net = CNN()
% optimizer = torch.optim.Adamax(net.parameters())
% loss_func = torch.nn.L1Loss()
% epochnum = 10000
% for epoch in range(epochnum):
%     prediction = net(Xtrain_cnn)
%     loss = loss_func(Ytrain_nn, prediction)
%     optimizer.zero_grad()
%     loss.backward()
%     optimizer.step()
%     if epoch % (epochnum / 10) == 0:
%         print("epoch:", epoch, "loss:", loss.item())
% prediction = pd.DataFrame(net(Xtest_cnn).detach().numpy())
% Ypredict = prediction.idxmax(axis=1).map(lambda x: encode[x])
% result["CNN"] = get_score(Xtest, Ytest, lambda _: Ypredict)
% result["CNN"]
% \end{verbatim}

% 			增加网络层数可能会导致梯度离散和梯度爆炸的情况，反而效果不好。残差网络 ResNet 利用在网络间加入 shortcut ，使更深层次的训练结果至少不差于更浅层次（如果更差就直接走 shortcut ）
% 		\end{block}
% 		\begin{block}{RNN}
% 			\begin{center}
% 				\includegraphics[width=.9\linewidth]{/Users/dcy/.emacs.d/.local/cache/org-persist/e7/a5e28e-ecf0-4f90-b7d8-77777a921d3d-0ae5bdb1bc5eed3623ce9cfa0b704d21.jpg}
% 			\end{center}
% 			循环神经网络：常用在 NLP 中并大放异彩，也会应用在股价等时间序列中。他会短期地“记住”参数，就如同我说这句话的时候你短期地记住了上一句话，会更新“自我”而非直接向前传递，在该层中“循环”。即对于隐藏层而言，\(h_t = f_w(h_{t-1}, x_t)\) 。随着输入的更新，有一个短暂的 memory ，记住刚刚的参数。
% 			\begin{verbatim}

% class LSTM(nn.Module):
%     def __init__(self):
%         super(LSTM, self).__init__()
%         self.lstm = nn.LSTM(
%             input_size=1,
%             hidden_size=32,
%             num_layers=1,
%             batch_first=True,
%             bidirectional=True,
%         )
%         self.fc = nn.Linear(32* 2, num_classes)

%     def forward(self, x):
%         # x, _ = x
%         out, _ = self.lstm(x)
%         out = self.fc(out[:, -1, :])
%         return out


% input_size = 1
% hidden_size = 32
% num_layers = 1
% num_classes = 7
% net = LSTM()
% optimizer = torch.optim.Adamax(net.parameters())
% loss_func = nn.MSELoss()
% epochnum = 3000
% for epoch in range(epochnum):
%     out = net(Xtrain_nn.unsqueeze(2))
%     loss = loss_func(out, Ytrain_nn)
%     optimizer.zero_grad()
%     loss.backward()
%     optimizer.step()
%     if epoch % (epochnum / 10) == 0:
%         print("epoch:", epoch, "loss:", loss.item())

% prediction = pd.DataFrame(net(Xtest_nn.unsqueeze(2)).detach().numpy())
% Ypredict = prediction.idxmax(axis=1).map(lambda x: encode[x])
% result["RNN"] = get_score(Xtest, Ytest, lambda _: Ypredict)
% result["RNN"]
% \end{verbatim}

% 			但是 RNN 的的梯度非常容易“爆炸”（特别大）或“离散”（特别小以致于不更新），预测可能会出错。
% 			针对此，LSTM （Long Short Term Memory）模型设计了三个“门”：输入门 \texttt{i} ，遗忘门 \texttt{f} ，输出门 \texttt{o} ，有一篇非常好的\href{https://colah.github.io/posts/2015-08-Understanding-LSTMs/}{blog}详细描述了这些门是如何工作的，简而言之他加入了长期记忆的部分。
% 		\end{block}

% 		\begin{block}{GAN \& RL}
% 			\begin{itemize}
% 				\item 生成对抗网络：随机取样作为输入，其输出结果需要尽量模仿训练集中的真实样本，使判别网络无法判断生成网络的输出结果是否真实
% 				\item 强化学习：博弈论……
% 			\end{itemize}
% 			\begin{quote}
% 				强化学习（RL）是机器学习的一个领域，涉及软件代理如何在环境中采取行动以最大化一些累积奖励的概念。该问题由于其一般性，在许多其他学科中得到研究，如博弈论，控制理论，运筹学，信息论，基于仿真的优化，多智能体系统，群智能，统计和遗传算法。。在运筹学和控制文献中，强化学习被称为近似动态规划或神经动态规划。--Wikipedia
% 			\end{quote}
% 		\end{block}
% 	\end{block}

% 	\begin{block}{对比}
% 		\begin{verbatim}
% feature = ["precision", "recall", "f1", "\(R^2\)"]
% [["model"]+feature]+list([i[0]]+ [round(j,4) for j in i[1].values()] for i in result.items())
% \end{verbatim}

% 		\begin{verbatim}
% N = len(feature)
% angles = np.linspace(0, 2 * np.pi, N, endpoint=False)
% angles = np.concatenate((angles, [angles[0]]))
% fig = plt.figure()
% ax = fig.add_subplot(111, polar=True)
% for model in result:
%     values = [i for i in result[model].values()] + [result[model]["precision"]]
%     ax.plot(angles, values, label=model)
%     ax.fill(angles, values, alpha=0.1)
% ax.set_thetagrids(angles[:-1] * 180 / np.pi, feature)
% ax.grid(True)
% plt.legend(bbox_to_anchor=(1.2, -0.1), ncol=3)
% plt.show()
% \end{verbatim}
% 	\end{block}
% \end{frame}
\section{参考文献}
\begin{frame}{参考文献}
    \printbibliography
\end{frame}
\end{document}
